\chapter{Applicazione realizzata}
\label{cap:3}
Nel presente capitolo, sarà descritta dettagliatamente l'intera architettura software del sistema sviluppato. L'analisi si concentrerà sulle scelte implementative che hanno permesso di trasformare un framework di Object Detection generico in uno strumento utilizzabile in presenza di dati astrofisici. In particolare, saranno illustrate le modifiche apportate al codice sorgente di YOLOv7 per renderlo compatibile con il formato dei magnetogrammi, assieme al modo in cui sono state integrate le librerie ausiliarie per realizzare effettivamente il processo di predizione.

\section{Adattamento del modello YOLOv7}
Per poter utilizzare un modello preesistente come YOLOv7 nel dominio dell'astrofisica solare, il primo passo necessario è stato quello di creare un metodo che permettesse al framework di leggere e di interpretare un formato di dati per cui non è stato progettato. Quindi, in questa sezione, saranno esplicitate tutte le modifiche tecniche apportate a livello pratico al codice sorgente, in modo da superare questa limitazione e rendere il modello nella sua interezza compatibile con i dati scientifici HARP.
\subsection{Implementazione di un Data Loader per Dati Scientifici}
Come ampiamente anticipato, YOLOv7 è progettato per operare su un dataset di immagini tradizionali (es. \texttt{JPEG, PNG}), le cui annotazioni sono fornite in semplici formati di testo, in cui ogni riga contiene classe e coordinate normalizzate della bounding box. I dati HARP, invece, presentano una complessità strutturale che ne impedisce l'utilizzo diretto, data da:
\begin{itemize}
    \item \textbf{Formato contenitore:} i dati sono racchiusi da un formato \texttt{HDF5} (\texttt{.h5}), ovvero un file system gerarchico pensato per dati scientifici. All'interno del singolo file, i dati sono suddivisi in gruppi distinti e non solo come una semplice immagine.
    \item \textbf{Annotazioni implicite:} le coordinate delle bounding box non sono fornite esplicitamente, bensì è necessaria l'estrazione, partendo dagli attributi incastonati nella gerarchia del file.
\end{itemize}
Per superare l'incompatibilità tra le parti, è stato implementato \textit{ex novo} lo script\\
\texttt{utils/dataset\_h5.py}, il quale -non solo- agisce come \textit{traduttore specializzato} tra il formato specifico e l'input standard, ma implementa due strategie software avanzate per garantire maggiore efficienza e robustezza: un meccanismo di \textit{caching su disco} per accelerare gli avvii e una \textit{gestione delle eccezioni} per ignorare i file corrotti in fase di addestramento. Tali compiti sono eseguiti dalla \textbf{classe DatasetH5}, all'interno della quale, la logica è implementata nei due metodi principali:
\begin{itemize}
    \item \textbf{Metodo Costruttore (\textit{Caching Intelligente per l'Efficienza})}\\
    Il metodo \texttt{\_\_init\_\_} gestisce la pre-elaborazione di tutti i metadati del dataset. Per evitare l'onerosa ripetizione di tale operazione, che può richiedere anche ore, ad ogni avvio del training, è stata implementata una logica di \textit{caching}. I passi sono i seguenti:
    \begin{enumerate}
        \item \textbf{Verifica della Cache}: Come prima operazione, lo script controlla l'esistenza dei file \texttt{\_labels.npy} e \texttt{\_shapes.npy} nella cartella di appartenenza; essi sono progettati per contenere -rispettivamente- tutte le etichette elaborate e le dimensioni originali dell'immagine.
        \item \textbf{Caricamento Veloce (\textit{Cache Hit})}: Se i suddetti file esistono (pre-elaborazione già eseguita in passato), le informazioni sono caricate immediatamente in memoria tramite la funzione \texttt{np.load()}, riducendo il tempo di avvio da ore a pochi secondi: questo rende il processo di sperimentazione molto più agile.
        \item \textbf{Creazione della Cache (\textit{Cache Miss})}: Se i suddetti file non esistono (solitamente solo alla prima esecuzione), è avviato il processo di analisi completo. Si itera su ogni singolo file \texttt{.h5} e sono eseguite una serie di operazioni:
        \begin{enumerate}
            \item \textbf{Accesso e Navigazione}: è aperta la struttura interna del file e letta la matrice del magnetogramma dal percorso \texttt{/magnetogram/data}, memorizzando le dimensioni originali;
            \item \textbf{Parsing e Validazione dei Metadati}: lo script naviga fino al percorso \texttt{/harp/metadata} e itera su ogni sottogruppo, ciascuno dei quali rappresenta una regione attiva. Per ognuna di esse, è eseguito un procedimento di validazione per mantenere l'integrità dell'etichetta:
            \begin{enumerate}
                \item \textbf{Verifica di Completezza}: si controlla la presenza di tutti gli attributi necessari per la definizione delle bounding box: \texttt{CRPIX1} e \texttt{CRPIX2} (coordinate x e y del pixel di riferimento della regione), \texttt{CRSIZE1} e \texttt{CRSIZE2} (larghezza e altezza in pixel della regione).
                Se anche solo uno di questi attributi manca, la regione è scartata.
                \item \textbf{Verifica delle Dimensioni}: si controlla che i valori di \texttt{CRSIZE1} (larghezza) e \texttt{CRSIZE2} (altezza) siano strettamente maggiori di zero. Ovviamente, etichette con dimensioni nulle o negative sono considerate corrotte e, quindi, ignorate.
                \item \textbf{Verifica dei Limiti (\textit{Boundary Check})}: dopo aver calcolato le coordinate normalizzate del centro della bounding box, si verifica che queste rientrino effettivamente nei limti dell'immagine (comprese tra 0.0 e 1.0). Le etichette il cui centro cade al di fuori dei bordi vengono scartate: questo garantisce che solo le regioni con un centro visibile siano considerate valide, pur ammettendo quelle che potrebbero estendersi parzialmente oltre il bordo.
            \end{enumerate} 
            \item \textbf{Calcolo e Memorizzazione}: Solo una volta superati i controlli di validazione, le coordinate di una regione sono calcolate, trasformandole da un tipo \textit{"punto di origine + dimensioni"} ad un sistema del tipo \textit{"centro + dimensioni"} e memorizzate in una lista temporanea.
        \end{enumerate}
        \item \textbf{Salvataggio della Cache}: Al termine di questo lungo processo, le liste contenenti tutte le etichette e le dimensioni vengono salvate su disco nei rispettivi file \texttt{.npy}. In questo modo, la cache è creata e resterà disponibile per eventuali avvii futuri.
    \end{enumerate}
    \item \textbf{Metodo di Accesso ai Dati (\textit{Caricamento Robusto})}\\
    Il metodo \texttt{\_\_getitem\_\_} è chiamato ripetutamente durante il training da processi paralleli (\texttt{workers}) per caricare un singolo magnetogramma e prepararlo per il modello. La sua logica è resa robusta grazie al blocco \texttt{try...except} per garantire la stabilità dell'addestramento. All'interno del suddetto metodo, sono eseguite una serie di operazioni:
    \begin{enumerate}
        \item \textbf{Lettura del Dato}: Viene aperto il file \texttt{.h5} richiesto e ne legge i dati relativi al magnetogramma. Poichè questa è l'operazione più a rischio in caso di file corrotti, viene effettuato il \texttt{try...except}.
        \item \textbf{Pre-processing}: Se la lettura ha successo, il magnetogramma è sottoposto ad una serie di trasformazioni, in modo da renderlo un input valido ed efficace per la rete neurale:
        \begin{enumerate}
            \item \textbf{Pulizia dei Valori Anormali}: I dati scientifici possono contenere valori non validi come \texttt{Nan} (Not A Number) o \texttt{inf} (infinito), spesso causati da errori di misurazione o di calcolo. Non essendo valori numericamente stabili, se passati ad una rete neurale, causerebbero un fallimento nel processo di training. Per questo, è eseguita una pulizia preventiva tramite la funzione \texttt{np.nan\_to\_num}, che sostituisce le eventuali occorrenze di tali valori con il valore neutro \texttt{(0.0)}.
            \item \textbf{Clipping dei Valori}: I magnetogrammi presentano una notevole variazione di intensità tra le diverse aree, ma i valori più significativi per l'identificazione delle regioni attive si trovano in un intervallo specifico, mentre, invece, valori oltremodo alti/bassi rappresentano -nella maggior parte dei casi- rumori. Per questo motivo è necessaria un'operazione di \textit{clipping} mediante la funzione \texttt{np.clip()} della libreria \texttt{NumPy}: essa "taglia" i valori del magnetogramma, forzando tutti i pixel al di fuori a rientrare nell'intervallo predefinito, aiutando, in questo modo, il modello a concentrarsi sulle caratteristiche più significative.
            \item \textbf{Normalizzazione Min-Max}: Poichè le reti neurali apprendono più efficientemente quando i dati in input sono scalati in un intervallo piccolo, si applica una normalizzazione che riscala tutti i valori dei pixel all'interno dell'intervallo \texttt{[0,1]}, garantendo la stessa scala di valori che -in questo modo- accelera la convergenza del training.
            \item \textbf{Ridimensionamento}: YOLOv7 richiede che la dimensione di input sia 640x640, quindi, i magnetogrammi sono ridimensionati mediante la funzione \texttt{cv2.resize()}, mediante l'utilizzo di un'interpolazione lineare che rappresenta un ottimo compromesso tra qualità visiva e velocità di calcolo.
            \item \textbf{Conversione a 3 Canali}: Dato che YOLOv7 accetta unicamente immagini a tre canali, è stato necessario rendere i magnetogrammi (a singolo canale) compatibili, per cui il canale unico è stato duplicato tre volte mediante la funzione \texttt{np.stack()}. Ciò significa che non viene aggiunta informazione, ma c'è un semplice riadattamento del dato all'input richiesto dal modello. Infine, avviene la conversione in un tensore PyTorch nel formato \texttt{[Canali, Altezza, Larghezza]}.
        \end{enumerate}
        \item \textbf{Gestione dell'Errore}: Se una qualsiasi operazione sul file fallisce, viene cattura l'eccezione. Piuttosto che interrompere l'intero training, lo script stampa a video un avviso con il nome del file problematico e restituisce un tensore  di zeri (corrispondente ad un'immagine nera).
    \end{enumerate}
La struttura così descritta rende l'intero processo efficiente in termini di tempo e robusto in caso di errori nel dataset. Il tutto è stato fondamentale per l'intero progetto: i dati scientifici sono stati utilizzati come se fossero immagini.\\
Di seguito, è riportato il codice sorgente dello script.\\

\begin{lstlisting}[language=Python,caption={[dataset\_h5.py]Implementazione commentata della classe \texttt{DatasetH5}. Ogni riga di codice e' accompagnata da una spiegazione per illustrare in dettaglio il processo di caricamento, validazione e pre-elaborazione dei dati dei magnetogrammi.},label={lst:dataset_h5_commentato}]
# File: dataset_h5.py

# --- BLOCCO IMPORTAZIONI ---
import torch  # Libreria principale per il deep learning.
from torch.utils.data import Dataset  # Classe base di PyTorch per creare dataset personalizzati.
import h5py  # Libreria specifica per leggere file in formato HDF5.
import numpy as np  # Libreria per il calcolo numerico, usata per manipolare gli array di dati.
import cv2  # Libreria OpenCV per operazioni sulle immagini, come il ridimensionamento.
import os  # Libreria per interagire con il sistema operativo (es. gestire percorsi).
import glob  # Libreria per trovare file che corrispondono a un pattern.
from tqdm import tqdm  # Libreria per gestire visivamente barre di avanzamento.

# --- DEFINIZIONE DELLA CLASSE DATASET ---
# Eredita da 'Dataset' di PyTorch per integrarsi con i suoi strumenti, come il DataLoader.
class DatasetH5(Dataset):
    # --- METODO COSTRUTTORE (`__init__`) ---
    # Viene eseguito una sola volta all'inizio. Prepara il dataset.
    def __init__(self, path, img_size=640, clip_range=(-1500, 1500)):
        # Salva i parametri di configurazione come attributi della classe.
        self.img_size = img_size  # Dimensione finale delle immagini.
        self.clip_min, self.clip_max = clip_range  # Intervallo per il clipping dei valori dei pixel.
        self.class_id = 0  # ID di classe fisso (0), dato che abbiamo solo una classe ("regione attiva").
        
        # --- LOGICA DI CACHING ---
        # Definisce una sottocartella 'cache' dove verranno salvati i dati pre-elaborati.
        cache_dir = 'cache'
        # Crea la cartella 'cache' se non esiste gia'. 'exist_ok=True' evita errori se la cartella esiste.
        os.makedirs(cache_dir, exist_ok=True)
        
        # Costruisce un nome univoco per i file di cache basato sul nome della cartella dei dati (es. "Train" o "Validation").
        cache_name = os.path.basename(os.path.normpath(path))
        # Crea il percorso completo per il file di cache delle etichette (es. 'cache/Train_labels.npy').
        label_cache = os.path.join(cache_dir, f'{cache_name}_labels.npy')
        # Crea il percorso completo per il file di cache delle dimensioni originali delle immagini.
        shape_cache = os.path.join(cache_dir, f'{cache_name}_shapes.npy')

        # Cerca tutti i file .h5 nel percorso dato, li ordina e ne salva la lista.
        self.h5_files = sorted(glob.glob(os.path.join(path, '*.h5')))
        # Salva il numero totale di file trovati.
        self.n = len(self.h5_files)

        # Controlla se entrambi i file di cache esistono gia'.
        if os.path.exists(label_cache) and os.path.exists(shape_cache):
            # --- CARICAMENTO VELOCE DA CACHE (AVVVII SUCCESSIVI) ---
            print(f"Caricamento rapido da cache per '{cache_name}'...")
            # Carica l'array delle etichette dal file .npy. 'allow_pickle=True' e' necessario perche' le etichette sono in una lista di array.
            self.labels = np.load(label_cache, allow_pickle=True)
            # Carica l'array delle dimensioni dal file .npy.
            self.shapes = np.load(shape_cache)
            print(f"Cache caricata per {len(self.labels)} file. Avvio del training...")
        else:
            # --- CREAZIONE DELLA CACHE (PRIMO AVVIO LENTO) ---
            print(f"Cache non trovata. Creazione della cache per '{cache_name}' (lento solo la prima volta)...")
            
            # Inizializza le liste che conterranno i dati estratti.
            self.labels = []
            self.shapes = []
            bad_labels_count = 0  # Contatore per le etichette scartate.
            
            # Itera su ogni file .h5 trovato, mostrando una barra di avanzamento.
            for h5_path in tqdm(self.h5_files, desc=f"Caching metadata from {path}"):
                try:  # Blocco per gestire errori di lettura dei singoli file.
                    # Apre il file .h5 in modalita' lettura. 'with' assicura la chiusura automatica.
                    with h5py.File(h5_path, 'r') as f:
                        # Estrae il dataset del magnetogramma.
                        magnetogram_data = f['magnetogram/data']
                        # Legge le dimensioni originali (altezza, larghezza).
                        orig_h, orig_w = magnetogram_data.shape
                        # Aggiunge le dimensioni alla lista 'self.shapes'.
                        self.shapes.append([orig_h, orig_w])

                        # Accede al gruppo dei metadati HARP.
                        harp_group = f['harp/metadata']
                        image_labels = []  # Lista temporanea per le etichette di questa immagine.
                        
                        # Itera su ogni regione attiva trovata nei metadati.
                        for harp_id in harp_group:
                            # Estrae gli attributi della regione attiva corrente.
                            harp_attrs = harp_group[harp_id].attrs
                            
                            # Definisce le chiavi necessarie per calcolare una bounding box.
                            required_keys = ['CRPIX1', 'CRPIX2', 'CRSIZE1', 'CRSIZE2']
                            # Controlla se tutti gli attributi necessari sono presenti.
                            if not all(key in harp_attrs for key in required_keys):
                                continue  # Se ne manca uno, salta questa regione.

                            # Converte le dimensioni in numeri decimali.
                            w_abs = float(harp_attrs['CRSIZE1'])
                            h_abs = float(harp_attrs['CRSIZE2'])

                            # Controlla che le dimensioni siano positive.
                            if w_abs <= 0 or h_abs <= 0:
                                bad_labels_count += 1
                                continue  # Se non lo sono, scarta l'etichetta.

                            # Calcola le coordinate del centro e le dimensioni, normalizzandole rispetto alle dimensioni dell'immagine (sommando meta' della larghezza/altezza alla coordinata di origine CRPIX).
                            x_center_norm = float(harp_attrs['CRPIX1']) / orig_w
                            y_center_norm = float(harp_attrs['CRPIX2']) / orig_h
                            width_norm = w_abs / orig_w
                            height_norm = h_abs / orig_h

                            # Controlla che il centro della bounding box sia dentro l'immagine.
                            if not (0.0 < x_center_norm < 1.0 and 0.0 < y_center_norm < 1.0):
                                bad_labels_count += 1
                                continue  # Se e' fuori, scarta l'etichetta.
                            
                            # Aggiunge l'etichetta valida (formato YOLO) alla lista temporanea.
                            image_labels.append([self.class_id, x_center_norm, y_center_norm, width_norm, height_norm])
                        
                        # Aggiunge le etichette di questa immagine alla lista principale.
                        self.labels.append(np.array(image_labels, dtype=np.float32) if image_labels else np.empty((0, 5), dtype=np.float32))

                except Exception as e:  # Se si verifica un errore grave durante la lettura.
                    print(f"Errore grave durante la lettura del file {h5_path}: {e}")
                    # Aggiunge placeholder per mantenere l'allineamento degli indici.
                    self.labels.append(np.empty((0, 5), dtype=np.float32))
                    self.shapes.append([0, 0])

            # Stampa un riepilogo delle etichette scartate, se ce ne sono.
            if bad_labels_count > 0:
                print(f"ATTENZIONE: Trovate e scartate {bad_labels_count} etichette corrotte.")

            # Converte la lista di liste 'self.shapes' in un unico array NumPy.
            self.shapes = np.array(self.shapes, dtype=np.float64)
            
            # SALVA I DATI PROCESSATI NELLA CACHE PER USO FUTURO.
            print(f"Salvataggio della cache in '{path}'...") # NOTA: Stampa il percorso dei dati, non della cache
            np.save(label_cache, self.labels)  # Salva le etichette.
            np.save(shape_cache, self.shapes)  # Salva le dimensioni.
            print("Cache creata. I prossimi avvii saranno istantanei.")

    # --- METODO `__len__` ---
    # Restituisce il numero totale di campioni nel dataset.
    def __len__(self):
        return self.n  # Restituisce il numero di file contati all'inizio.

    # --- METODO `__getitem__` ---
    # Carica e restituisce un singolo campione (immagine + etichetta) dato un indice.
    def __getitem__(self, index):
        # Ottiene percorso e etichette pre-caricate per l'indice richiesto.
        h5_path = self.h5_files[index]
        labels_tensor = torch.from_numpy(self.labels[index])
        
        try:  # Blocco per gestire errori di apertura file (es. file corrotti).
            # Tenta di aprire il file H5 e leggere i dati dell'immagine.
            with h5py.File(h5_path, 'r') as f:
                data = f['magnetogram/data'][:]  # Carica l'intero array in memoria.

            # Pulisce i dati da eventuali valori non numerici (NaN/inf).
            if np.isnan(data).any() or np.isinf(data).any():
                data = np.nan_to_num(data, nan=0.0, posinf=0.0, neginf=0.0)
            
            # Pre-processa l'immagine: clipping, normalizzazione e ridimensionamento.
            clipped_data = np.clip(data, self.clip_min, self.clip_max)
            normalized_data = (clipped_data - self.clip_min) / (self.clip_max - self.clip_min)
            resized_image = cv2.resize(normalized_data, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)
            
            # Converte a 3 canali (duplicando il canale unico) per compatibilita' con YOLOv7.
            image_rgb = np.stack([resized_image] * 3, axis=-1)
            # Converte l'array NumPy in un tensore PyTorch e riordina le dimensioni in [C, H, W].
            image_tensor = torch.from_numpy(image_rgb.transpose(2, 0, 1)).float()
            
            # Restituisce il campione completo.
            return image_tensor, labels_tensor, h5_path, self.shapes[index]

        except Exception as e:  # Se si verifica un qualsiasi errore durante il caricamento.
            # Stampa un avviso e ignora il dato corrotto.
            print(f"\nATTENZIONE: Ignorato file corrotto o illeggibile: {os.path.basename(h5_path)}")
            
            # Restituisce un'immagine nera per non interrompere il training.
            placeholder_image = torch.zeros((3, self.img_size, self.img_size))
            return placeholder_image, labels_tensor, h5_path, self.shapes[index]
\end{lstlisting}

\subsection{Integrazione del Data Loader nella Logica di Training}
La creazione di un data loader personalizzato è un passo necessario, ma non sufficiente per il completo riadattamento del modello, la logica appena descritta necessita di essere integrata nel flusso di lavoro. Per questo motivo, la decisione più adeguata è stata quella di intervenire direttamente sul codice sorgente di YOLOv7, in particolare su quegli script che sono responsabili dell'addestramento e della validazione del modello.

\subsubsection{Adattamento della Logica di Training}
La creazione del nuovo Data Loader ha richiesto alcune modifiche allo script \texttt{train.py}, che rappresenta il motore del processo di training. L'obiettivo principale era quello di permettere al modello di scegliere dinamicamente quale loader utilizzare -quello di default per immagini standard o quello personalizzato per i dati HDF5- senza alterare la logica del ciclo di addestramento. Per ottenere ciò, sono state apportate le seguenti modifiche:
\begin{itemize}
    \item \textbf{Importazione condizionale} È stata importata la classe \texttt{DatasetH5} dallo script \texttt{utils/dataset\_h5.py}, in modo da renderla disponibile al momento della creazione del dataset.
    \begin{lstlisting}[language=Python, caption={[Importazione condizionale in train.py] Importazione della classe \texttt{DatasetH5} personalizzata.}, label={lst:import_dataset_h5}]
# Importa la classe personalizzata per la gestione dei dataset in formato HDF5.
from utils.dataset_h5 import DatasetH5
\end{lstlisting}
\item \textbf{Implementazione di una Funzione collate Personalizzata} \\
    L'implementazione della funzione \texttt{h5\_collate\_fn} è stata necessaria affinchè l'assemblaggio dei dati in batch avvenisse correttamente. Quando il Data Loader raggruppa più campioni per formare un batch, il modello deve essere in grado di effettuare un'associazione univoca tra ogni set di etichette (ovvero le coordinate delle bounding box) ed i relativi magnetogrammi di origine. Il compito principale della funzione è proprio quello di aggiungere a ciascuna etichetta un indice numerico che corrisponde alla posizione dell'immagine all'interno del batch; così facendo, il formato delle etichette è trasformato per includere tale indicatore, risolvendo ogni ambiguità. Questo ordinamento è necessario per permettere al ciclo di addestramento di confrontare le predizioni del modello con le etichette reali per ogni singolo magnetogramma, garantendo il corretto funzionamento dell'intero processo di apprendimento.
    \begin{lstlisting}[language=Python, caption={[Funzione h5\_collate\_h5 in train.py] Implementazione di una Funzione collate Personalizzata h5\_collate\_h5 in train.py}, label={lst:import_dataset_h5}]
def h5_collate_fn(batch):
    imgs, labels, paths, shapes = zip(*batch)
    batched_labels = []
    for i, label in enumerate(labels):
        if label.shape[0] > 0:
            batch_idx = torch.full((label.shape[0], 1), i, device=imgs[0].device)
            label_with_batch_idx = torch.cat((batch_idx, label.to(imgs[0].device)), 1)
            batched_labels.append(label_with_batch_idx)
    if len(batched_labels) > 0:
        targets = torch.cat(batched_labels, 0)
    else:
        targets = torch.empty(0, 6, device=imgs[0].device)
    return torch.stack(imgs, 0), targets, paths, shapes
logger = logging.getLogger(__name__)
\end{lstlisting}
    \item \textbf{Attivazione tramite file di configurazione} \\
    Per integrare il nuovo Data Loader, piuttosto che utilizzare un argomento da riga di comando, è stato implementato un meccanismo di \textit{attivazione contestuale} basato sul file di configurazione del dataset. All'avvio, lo script ispeziona il file \texttt{.yaml} fornito tramite argomento \texttt{-{}-data} alla ricerca della chiave booleana \texttt{is\_h5}: se è impostata su \texttt{True}, il framework capisce che deve gestire un dataset in formato \texttt{.h5} e attiva automaticamente il dataset personalizzato
    \begin{lstlisting}[language=Python, caption={[Attivazione DataLoader in train.py] Attivazione tramite file di configurazione nello script train.py}, label={lst:activate_dataset_h5}]
# Apre e legge il file di configurazione del dataset (es. harp.yaml)
with open(opt.data) as f:
    data_dict = yaml.load(f, Loader=yaml.SafeLoader)

# Controlla se la chiave 'is_h5' esiste e ha valore True; altrimenti, imposta False
is_h5_dataset = data_dict.get('is_h5', False)
\end{lstlisting}
    \item \textbf{Iniezione della logica di caricamento dati} Il cambiamento più significativo è avvenuto nella sezione in cui è creato l'oggetto \texttt{dataset}, grazie all'inserimento di una struttura condizionale \texttt{if-else} che controlla il valore dell'opzione \texttt{-{}-h5}: 
    \begin{itemize}
        \item se attivata, lo script ignora il loader di default \texttt{LoadImagesAndLabels} e istanzia la classe \texttt{DatasetH5}, passandole i parametri necessari (es. percorso ai dati, dimensione di immagini); 
        \item se disattivata, lo script maniene il suo comportamento originale.
    \end{itemize}
    \begin{lstlisting}[language=Python, caption={[Iniezione della logica di caricamento dati in train.py] Logica condizionale per la selezione dinamica del data loader in \texttt{train.py}.}, label={lst:dataloader_choice}]
# Controlla se l'opzione '--h5' e' stata attivata dalla riga di comando.
if opt.h5:
    # Se opt.h5 e' True, crea un'istanza del data loader personalizzato per i file HDF5.
    dataset = DatasetH5(
        train_path,      # Passa il percorso alla cartella contenente i file .h5.
        img_size=imgsz   # Passa la dimensione a cui verranno ridimensionate le immagini.
    )
# Altrimenti, se l'opzione '--h5' non e' stata attivata...
else:
    # ...esegue il codice originale, creando un'istanza del data loader di default di YOLOv7.
    dataset = LoadImagesAndLabels(
        train_path,          
        imgsz,               
        batch_size,          
        augment=True,        
        hyp=hyp,             
        rect=opt.rect,       
        cache_images=opt.cache_images, 
        single_cls=opt.single_cls,    
        stride=int(stride),  
        pad=0.0,             
        image_weights=opt.image_weights, 
        prefix=colorstr('train: ')     
    )
\end{lstlisting}
\end{itemize}
L'approccio appena descritto ed adottato per lo scopo è noto come \textit{feature flagging}: si tratta di una tecnica di sviluppo software che permette -all'occorrenza- di attivare/disattivare funzionalità specifiche di un'applicazione senza dover modificare il codice sorgente per intero, ma solo in modo mirato. In questo modo, è stato possibile estendere la funzionalità di YOLOv7 in modo modulare, rimanendo coerente al funzionamento originale e garantendo che la nuova logica sia eseguita solo quando esplicitamente richiesto.

\subsubsection{Estensione della Logica di Validation}
Per mantenere una coerenza all'interno del modello e per garantire che non ci siano conflitti in fase di validazione, è stato necessario apportare modifiche anche allo script \texttt{test.py}. Un modello addestrato deve necessariamente essere validato utilizzando lo stesso processo di caricamento e pre-elaborazione. Per questo motivo, sono state effettuate alcune modifiche simili rispetto a quelle apportate in \texttt{train.py}:
\begin{itemize}
       \item \textbf{Importazione condizionale}\\
       È stata aggiunta l'istruzione per importare la classe \texttt{DatasetH5} dallo script \texttt{utils/dataset\_h5.py}, in modo da renderla disponibile nello script di validazione, assieme alla funzione \texttt{degault\_collate} di default di PyTorch per assemblare i batch ed importata per essere utilizzata nella funzione \texttt{h5\_collate\_fn}.
    \begin{lstlisting}[language=Python, caption={[Importazione condizionale in test.py] Importazione della classe \texttt{DatasetH5} personalizzata.}, label={lst:import_dataset_h5_2}]
# Importa la classe personalizzata per la gestione dei dataset in formato HDF5.
from utils.dataset_h5 import DatasetH5

# Importa la funzione di default di PyTorch per l'assemblaggio dei batch.
from torch.utils.data.dataloader import default_collate
\end{lstlisting}
    \item \textbf{Implementazione di una Funzione collate Personalizzata} Analogamente allo script di training, è stata aggiunta una funzione \texttt{h5\_collate\_fn} semplificata, con lo scopo di raggruppare i singoli campioni caricati dalla classe \texttt{DatasetH5} in un unico batch. D'altronde, durante la fase di training, tale funzione doveva necessariamente aggiungere l'indice del batch ad ogni etichetta per il calcolo della loss; durante la fase di validazione, tale passaggio non è più necessario. Pertanto, per mantenere l'efficienza, la funzione si occupa semplicemente di impilare i tensori in modo standard.
    \begin{lstlisting}[language=Python, caption={[Funzione h5\_collate\_h5 in test.py] Implementazione di una Funzione collate Personalizzata h5\_collate\_h5 in test.py}, label={lst:h5_arg}]
def h5_collate_fn(batch):
    """Funzione custom per raggruppare i dati provenienti da DatasetH5 in un batch."""
    return default_collate(batch)
\end{lstlisting}
    \item \textbf{Aggiunta di un Parametro}\\
    La funzione principale \texttt{test} è stata estesa per accettare un nuovo argomento booleano \texttt{is_magnetogram}. Lo scopo è di fungere da "flag" interno. Esso è passato dallo script \texttt{train.py} durante la validazione, a fine epoca, per informare la funzione \texttt{test} che sta per ricevere dati di tipo magnetogramma piuttosto che immagini standard. Il meccanismo è il seguente: non si attiva il caricamento dei dati H5, bensì controlla i comportamenti successivi (ad esempio la normalizzazione delle immagini e la visualizzazione dei risultati), assicurando che vengano trattati come dati scientifici.
    \begin{lstlisting}
        [language=Python, caption={[Aggiunta del Parametro in test.py] Aggiunta del parametro is\_magnetogram in test.py}, label={lst:h5_arg}]
        def test(data,
         ...,
         is_magnetogram=False):
    \end{lstlisting}
    \item \textbf{Creazione Dinamica del Data Loader} \\
    Con il seguente blocco, si vuole rendere lo script flessibile, in grado sia di validare il dataset standard che quello H5 senza modifiche manuali. Legge il file di configurazione \texttt{.yaml} del dataset e cerca la chiave \texttt{is\_h5}: se è \texttt{True}, istanzia la classe \texttt{DatasetH5} e crea un Data Loader di PyTorch che la utilizza assieme alla \texttt{h5\_collate\_fn} semplificata; se \texttt{False} o non presente, lo script esegue la funzione originale \texttt{create\_dataloader}, mantenendo a pieno la compatibilità con dataset di immagini tradizionali.
    \begin{lstlisting}[language=Python, caption={[Creazione Dinamica del Data Loader in test.py] Introduzione di una logica condizionale per scegliere dinamicamente quale data loader utilizzare in test.py}, label={lst:h5_arg}]
    is_h5_dataset = data.get('is_h5', False)
        if is_h5_dataset:
            print("Utilizzo del DataLoader custom per dataset .h5")
            dataset = DatasetH5(path=data[task], img_size=imgsz)
            dataloader = torch.utils.data.DataLoader(dataset,
                                                    batch_size=batch_size,
                                                    shuffle=False,
                                                    num_workers=8, # Puoi usare opt.workers se disponibile
                                                    pin_memory=True,
                                                    collate_fn=h5_collate_fn)
        else:
            # Logica originale di YOLOv7
            dataloader = create_dataloader(data[task], imgsz, batch_size, gs, opt, pad=0.5, rect=True,
                                        prefix=colorstr(f'{task}: '))[0]
\end{lstlisting}
\item \textbf{Normalizzazione Condizionale delle Immagini} \\
Per evitare di processare i dati erroneamente, la normalizzazione dei valori dei pixel è applicata in modo selettivo, così da non ricadere in una "doppia normalizzazione". Sappiamo che le immagini standard hanno valori di pixel nell'intervallo [0,255], mentre i magnetogrammi sono normalizzati già nella classe \texttt{DatasetH5} (tramite clipping e scalatura min-max): è per questo che la flag \texttt{is\_magnetogram} agisce, proprio per assicurare che divisione per 255.0 sia saltata quando si tratta di dati scientifici, preservando la corretta scala dei valori.
\begin{lstlisting}
    [language=Python, caption={[Normalizzazione Condizionale delle Immagini in test.py] Aggiunta del controllo su is\_magnetogram in test.py}, label={lst:h5_arg}]
    if not is_magnetogram:
            img /= 255.0 
\end{lstlisting}
\item \textbf{Adattamento delle Funzioni di Visualizzazione} \\
Infine, per garantire che i risultati della validazione siano visivamente corretti ed interpretabili, sono state modificate le chiamate alle funzioni di plotting.
\begin{lstlisting}
    [language=Python, caption={[Adattamento delle Funzioni di Visualizzazione in test.py] Modifica della chiamata alla funzione di plotting in test.py}, label={lst:h5_arg}]
    Thread(target=plot_images, args=(img, targets, paths, f, names), kwargs={'is_magnetogram': is_magnetogram}, daemon=True).start()
\end{lstlisting}
\end{itemize}

\subsubsection{Personalizzazione delle Utility di Visualizzazione}
L'ultimo passo dell'adattamendo del framework è stata inerente alla visualizzazione corretta dei risultati. Le funzioni di plotting standard di YOLOv7, contenute nel modulo \texttt{utils/plots.py}, sono state progettate per operare su immagini a tre canali (BGR). Tuttavia, i magnetogrammi sono immagini a singolo canale, in cui ogni pixel ha un valore di intensità. Applicare direttamente la funzione originale a questi dati avrebbe comportato una visualizzazione non corretta dal punto di vista cromatico, o anche un errore. Per risolvere tale problema, è stata modificata la funzione \texttt{plot\_images}, introducendo una \textit{logica condizionale} che ispeziona le dimensioni del tensore dell'immagine in input:
\begin{itemize}
    \item \textbf{Caso standard - 3 canali (BGR)} In presenza di un'immagine a 3 canali, lo script mantiene il comportamento originale, effettuando la conversione da BGR a RGB.
    \item \textbf{Caso personalizzato - 1 canale} In presenza di un'immagine a singolo canale, la logica è la seguente:
    \begin{itemize}
        \item Rimuove la dimensione del canale mediante comando \texttt{squeeze()}, trasformando il tensore in una matrice 2D.
        \item Utilizza la libreria \texttt{matplotlib} per visualizzare la matrice come un'immagine in scala di grigi (\texttt{cmap='gray'}).
    \end{itemize}
\end{itemize}
\begin{lstlisting}[language=Python, caption={[Personalizzazione delle Utility di Visualizzazione in plots.py] Logica condizionale per la visualizzazione di immagini a singolo canale (scientifiche) e a tre canali (standard).}, label={lst:plot_logic}]
# Controlla se la prima dimensione del tensore dell'immagine e' 1 (ovvero, se ha un solo canale).
if img.shape[0] == 1:
    # --- Blocco per immagini a singolo canale ---
    
    # Converte l'array NumPy dell'immagine in un tensore di PyTorch.
    im = torch.from_numpy(img)
    
    # Disegna l'immagine usando matplotlib:
    # im.squeeze(0) rimuove la dimensione del canale (da [1, H, W] a [H, W]), necessaria per imshow.
    # cmap='gray' imposta la mappa di colori in scala di grigi, corretta per dati scientifici.
    plt.imshow(im.squeeze(0), cmap='gray')

# Altrimenti, se l'immagine ha piu' di un canale (si assume 3 canali).
else:
    # Esegue la funzione originale di YOLOv7
    img = img[..., ::-1].transpose(2, 0, 1)
    img = np.ascontiguousarray(img)
    im = torch.from_numpy(img)
\end{lstlisting}

\section{Tracking Multi-Oggetto con Norfair}
Solo dopo aver terminato l'adattamento di YOLOv7, è stato possibile sviluppare un'applicazione in grado di utilizzare il suddetto modello addestrato per eseguire un'analisi temporale. Prendendo come base lo script dimostrativo ufficiale fornito da Norfair per l'integrazione con YOLOv7, è stato sviluppato lo script \texttt{track.py}, con una logica implementativa che si adatta con coerenza allo scopo. L'intera sezione, quindi, descrive la struttura di tale script per il tracciamento multi-oggetto su una sequenza di magnetogrammi.
